#Lo primero que haremos será instalar el pack de basemap.  \
    #¡OJO! Este pack no funciona con posteriores versiones de matplotlib (3.2), de modo que si tiene una versión superior asegúrese de pasar a una versión compatible:
      pip install -U matplotlib==3.2
!conda install -c conda-forge  basemap matplotlib==3.2 -y

#A continuación, importamos las bibliotecas que utillizaremos
import numpy as np 
from sklearn.cluster import DBSCAN 
from sklearn.datasets.samples_generator import make_blobs 
from sklearn.preprocessing import StandardScaler 
import matplotlib.pyplot as plt 
%matplotlib inline

#Ahora, para ver cómo funciona DBSCAN, vamos a probar con un set de datos meteorológicos que aplicaremos a un mapa para fijar los clústers.
#Primero, descargamos los datos.
!wget -O weather-stations20140101-20141231.csv https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%204/data/weather-stations20140101-20141231.csv

#Cargamos el set de datos en un dataframe y echamos un primer vistazo
import csv
import pandas as pd
import numpy as np

filename='weather-stations20140101-20141231.csv'
pdf = pd.read_csv(filename)
pdf.head(5)

#A continuación, limpiamos los datos
pdf = pdf[pd.notnull(pdf["Tm"])]
pdf = pdf.reset_index(drop=True)
pdf.head(5)

#Vamos a echar una primera ojeada a la distribución de nuestros datos sobre el mapa
from mpl_toolkits.basemap import Basemap
import matplotlib.pyplot as plt
from pylab import rcParams
%matplotlib inline
rcParams['figure.figsize'] = (14,10)

llon=-140
ulon=-50
llat=40
ulat=65

pdf = pdf[(pdf['Long'] > llon) & (pdf['Long'] < ulon) & (pdf['Lat'] > llat) &(pdf['Lat'] < ulat)]

my_map = Basemap(projection='merc',
            resolution = 'l', area_thresh = 1000.0,
            llcrnrlon=llon, llcrnrlat=llat, #min longitude (llcrnrlon) and latitude (llcrnrlat)
            urcrnrlon=ulon, urcrnrlat=ulat) #max longitude (urcrnrlon) and latitude (urcrnrlat)

my_map.drawcoastlines()
my_map.drawcountries()
# my_map.drawmapboundary()
my_map.fillcontinents(color = 'white', alpha = 0.3)
my_map.shadedrelief()

#Las siguientes lineas sirven para localizar los datos basándose en las estaciones meteorológicas 
#   x,y = my_map(row.Long, row.Lat)
xs,ys = my_map(np.asarray(pdf.Long), np.asarray(pdf.Lat))
pdf['xm']= xs.tolist()
pdf['ym'] =ys.tolist()

#Visualización 1
for index,row in pdf.iterrows():
   my_map.plot(row.xm, row.ym,markerfacecolor =([1,0,0]),  marker='o', markersize= 5, alpha = 0.75)
plt.show()


#Ahora vamos a crear clusters basándonos en la longitud y la latitud de las estaciones que hemos visto en el paso anterior
from sklearn.cluster import DBSCAN
import sklearn.utils
from sklearn.preprocessing import StandardScaler
sklearn.utils.check_random_state(1000)
Clus_dataSet = pdf[['xm','ym']]
Clus_dataSet = np.nan_to_num(Clus_dataSet)
Clus_dataSet = StandardScaler().fit_transform(Clus_dataSet)

#Con las siguientes lineas llevamos a cabo la computación con DBSCAN
db = DBSCAN(eps=0.15, min_samples=10).fit(Clus_dataSet)
core_samples_mask = np.zeros_like(db.labels_, dtype=bool)
core_samples_mask[db.core_sample_indices_] = True
labels = db.labels_
pdf["Clus_Db"]=labels

realClusterNum=len(set(labels)) - (1 if -1 in labels else 0)
clusterNum = len(set(labels)) 

#La siguiente linea ofrecerá una muestra de los clusters
pdf[["Stn_Name","Tx","Tm","Clus_Db"]].head(5)


#Veamos las étiquetas de clúster, teniendo en cuenta que los outliers (datos que no encajan en ningún clúster) tienen un valor de -1.
set(labels)
  #[OUT]: {-1, 0, 1, 2, 3, 4}
  
  
#Ahora que ya hemos agrupado nuestros datos con DBSCAN, ya podemos proyectar los clústeres en el mapa, así como consultar la media de cada clúster
from mpl_toolkits.basemap import Basemap
import matplotlib.pyplot as plt
from pylab import rcParams
%matplotlib inline
rcParams['figure.figsize'] = (14,10)

my_map = Basemap(projection='merc',
            resolution = 'l', area_thresh = 1000.0,
            llcrnrlon=llon, llcrnrlat=llat, #min longitude (llcrnrlon) and latitude (llcrnrlat)
            urcrnrlon=ulon, urcrnrlat=ulat) #max longitude (urcrnrlon) and latitude (urcrnrlat)

my_map.drawcoastlines()
my_map.drawcountries()
#my_map.drawmapboundary()
my_map.fillcontinents(color = 'white', alpha = 0.3)
my_map.shadedrelief()

 # Para crear un mapa de color
colors = plt.get_cmap('jet')(np.linspace(0.0, 1.0, clusterNum))



#Visualización 1
for clust_number in set(labels):
    c=(([0.4,0.4,0.4]) if clust_number == -1 else colors[np.int(clust_number)])
    clust_set = pdf[pdf.Clus_Db == clust_number]                    
    my_map.scatter(clust_set.xm, clust_set.ym, color =c,  marker='o', s= 20, alpha = 0.85)
    if clust_number != -1:
        cenx=np.mean(clust_set.xm) 
        ceny=np.mean(clust_set.ym) 
        plt.text(cenx,ceny,str(clust_number), fontsize=25, color='red',)
        #Para indicar la media de temperatura de cada clúster
        print ("Cluster "+str(clust_number)+', Avg Temp: '+ str(np.mean(clust_set.Tm)))
#[OUT]: Mapa y Cluster 0, Avg Temp: -5.538747553816046
               Cluster 1, Avg Temp: 1.9526315789473685
               Cluster 2, Avg Temp: -9.195652173913045
               Cluster 3, Avg Temp: -15.300833333333333
               Cluster 4, Avg Temp: -7.769047619047619        
    

#Si bien el anterior clústering fue bidimensional, esto es, se creo sobre dos características únicas, veamos a continuación uno que englobe más dimensiones. En esta ocasión, 5.
from sklearn.cluster import DBSCAN
import sklearn.utils
from sklearn.preprocessing import StandardScaler
sklearn.utils.check_random_state(1000)
Clus_dataSet = pdf[['xm','ym','Tx','Tm','Tn']]
Clus_dataSet = np.nan_to_num(Clus_dataSet)
Clus_dataSet = StandardScaler().fit_transform(Clus_dataSet)

db = DBSCAN(eps=0.3, min_samples=10).fit(Clus_dataSet)
core_samples_mask = np.zeros_like(db.labels_, dtype=bool)
core_samples_mask[db.core_sample_indices_] = True
labels = db.labels_
pdf["Clus_Db"]=labels

realClusterNum=len(set(labels)) - (1 if -1 in labels else 0)
clusterNum = len(set(labels)) 

pdf[["Stn_Name","Tx","Tm","Clus_Db"]].head(5)
        

#Y tras haber hecho la computación con DBSCAN, procedemos a la visualización de los datos, como antes
from mpl_toolkits.basemap import Basemap
import matplotlib.pyplot as plt
from pylab import rcParams
%matplotlib inline
rcParams['figure.figsize'] = (14,10)

my_map = Basemap(projection='merc',
            resolution = 'l', area_thresh = 1000.0,
            llcrnrlon=llon, llcrnrlat=llat, #min longitude (llcrnrlon) and latitude (llcrnrlat)
            urcrnrlon=ulon, urcrnrlat=ulat) #max longitude (urcrnrlon) and latitude (urcrnrlat)

my_map.drawcoastlines()
my_map.drawcountries()
#my_map.drawmapboundary()
my_map.fillcontinents(color = 'white', alpha = 0.3)
my_map.shadedrelief()

colors = plt.get_cmap('jet')(np.linspace(0.0, 1.0, clusterNum))

for clust_number in set(labels):
    c=(([0.4,0.4,0.4]) if clust_number == -1 else colors[np.int(clust_number)])
    clust_set = pdf[pdf.Clus_Db == clust_number]                    
    my_map.scatter(clust_set.xm, clust_set.ym, color =c,  marker='o', s= 20, alpha = 0.85)
    if clust_number != -1:
        cenx=np.mean(clust_set.xm) 
        ceny=np.mean(clust_set.ym) 
        plt.text(cenx,ceny,str(clust_number), fontsize=25, color='red',)
        print ("Cluster "+str(clust_number)+', Avg Temp: '+ str(np.mean(clust_set.Tm)))
 #[OUT]: Mapa + Cluster 0, Avg Temp: 6.221192052980132
                Cluster 1, Avg Temp: 6.790000000000001
                Cluster 2, Avg Temp: -0.49411764705882344
                Cluster 3, Avg Temp: -13.87720930232558
                Cluster 4, Avg Temp: -4.186274509803922
                Cluster 5, Avg Temp: -16.301503759398496
                Cluster 6, Avg Temp: -13.599999999999998
                Cluster 7, Avg Temp: -9.753333333333334
                Cluster 8, Avg Temp: -4.258333333333334      
