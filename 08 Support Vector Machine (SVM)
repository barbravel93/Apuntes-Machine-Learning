#Lo primero, como siempre, será descargar e importar las bibliotecas necesarias
!pip install scikit-learn==0.23.1

import pandas as pd
import pylab as pl
import numpy as np
import scipy.optimize as opt
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
%matplotlib inline 
import matplotlib.pyplot as plt

#A continuación descargamos los datos y los dataframeamos
!wget -O cell_samples.csv https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%203/data/cell_samples.csv

cell_df = pd.read_csv("cell_samples.csv")
cell_df.head()

#Podemos ojear gráficamente qué apariencia tienen nuestros datos, para hacernos una idea más visual
ax = cell_df[cell_df['Class'] == 4][0:50].plot(kind='scatter', x='Clump', y='UnifSize', color='DarkBlue', label='malignant');
cell_df[cell_df['Class'] == 2][0:50].plot(kind='scatter', x='Clump', y='UnifSize', color='Yellow', label='benign', ax=ax);
plt.show()

#Nos damos cuenta al ver el gráfico de que requeriremos de SVM para hacer la clasificación, de modo que nos ponemos a escribir el algoritmo.Pero antes, debemos preprocesar los datos
cell_df.dtypes
  #[OUT]: ID              int64
          Clump           int64
          UnifSize        int64
          UnifShape       int64
          MargAdh         int64
          SingEpiSize     int64
          BareNuc        object
          BlandChrom      int64
          NormNucl        int64
          Mit             int64
          Class           int64
          dtype: object
#Vemos que debemos cambiar BareNuc
cell_df = cell_df[pd.to_numeric(cell_df['BareNuc'], errors='coerce').notnull()]
cell_df['BareNuc'] = cell_df['BareNuc'].astype('int')

#Estamos listos para crear la matriz(array) con nuestros datos
feature_df = cell_df[['Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize', 'BareNuc', 'BlandChrom', 'NormNucl', 'Mit']]
X = np.asarray(feature_df)

#Asignamos también la clase de nuestra predicción, que será 2 o 4, benigno o maligno respectivamente en el ejemplo (trabajamos con datos sobre tumores)
cell_df['Class'] = cell_df['Class'].astype('int')
y = np.asarray(cell_df['Class'])

#Procesados los datos, llega el momento de dividirlos en set de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)
print ('Train set:', X_train.shape,  y_train.shape)
print ('Test set:', X_test.shape,  y_test.shape)

#Procedemos a hacer el modelado. Para ello podemos elegir entre cuatro tipos distintos de kernel (función matemática). 
 #\Lo ideal será probar cada uno para encontrar el que menos errores arroja (readme). En este ejemplo usaremos 'rbf' y 'linear', aunque también están 'polynomial' y 'sigmoid'.
from sklearn import svm
clf = svm.SVC(kernel='rbf')
clf.fit(X_train, y_train)

#Encajado el modelo, predecimos los nuevos valores
yhat = clf.predict(X_test)

#Llega el momento de la evaluación. Primero, descargamos las herramientas que necesitaremos
from sklearn.metrics import classification_report, confusion_matrix
import itertools

#Procedemos a trazar el matriz de confusión
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

# Computamos la matriz de confusión
cnf_matrix = confusion_matrix(y_test, yhat, labels=[2,4])
np.set_printoptions(precision=2)
print (classification_report(y_test, yhat)
  #[OUT]:              precision    recall  f1-score   support

                    2       1.00      0.94      0.97        90
                    4       0.90      1.00      0.95        47

            caccuracy                           0.96       137
            macro avg       0.95      0.97      0.96       137
         weighted avg       0.97      0.96      0.96       137

        Confusion matrix, without normalization:
        [[85  5]
        [ 0  47]]
        

# También desplegamos el gráfico
plt.figure()
plot_confusion_matrix(cnf_matrix, classes=['Benign(2)','Malignant(4)'],normalize= False,  title='Confusion matrix')

#También podemos obtener F1 score:
from sklearn.metrics import f1_score
f1_score(y_test, yhat, average='weighted') 
  #[OUT]: 0.9639038982104676

#O el Índice de Jaccard
from sklearn.metrics import jaccard_score
jaccard_score(y_test, yhat,pos_label=2)
  #[OUT]:0.9444444444444444
  
  
#Como antes se ha dicho, idealmente probaremos con los cuatro posibles kernels (funciones de SVM) para encontrar el que mejor resultados arroje. Probemos ahora con el lineal.
clf2 = svm.SVC(kernel='linear')
clf2.fit(X_train, y_train) 
yhat2 = clf2.predict(X_test)
print("Avg F1-score: %.4f" % f1_score(y_test, yhat2, average='weighted'))
print("Jaccard score: %.4f" % jaccard_score(y_test, yhat2,pos_label=2))
  #[OUT]: Avg F1-score: 0.9639  \  Jaccard score: 0.9444
