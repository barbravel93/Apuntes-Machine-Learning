#El primer paso será instalar e importar las bibliotecas necesarias
!pip install scikit-learn==0.23.1

import pandas as pd
import pylab as pl
import numpy as np
import scipy.optimize as opt
from sklearn import preprocessing
%matplotlib inline 
import matplotlib.pyplot as plt

#Descargamos el archivo con los datos
!wget -O ChurnData.csv https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%203/data/ChurnData.csv

#Cargamos los datos en un archivo CSV
churn_df = pd.read_csv("ChurnData.csv")
churn_df.head()

#Preprocesamos los datos, los limpiamos para que sean ints y seleccionamos las variables con las que vamos a trabajar
churn_df = churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip',   'callcard', 'wireless','churn']]
churn_df['churn'] = churn_df['churn'].astype('int')
churn_df.head()

#Ojeamos las dimensiones de nuestro set de datos
churn_df.shape

#Procedemos a definir nuestras variables X e Y
X = np.asarray(churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip']])
X[0:5]

y = np.asarray(churn_df['churn'])
y [0:5]

#También, normalizamos el set de datos
from sklearn import preprocessing
X = preprocessing.StandardScaler().fit(X).transform(X)
X[0:5]

#Procedemos a separar nuestro conjunto de datos en conjunto de entrenamiento y conjunto de prueba
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)
print ('Train set:', X_train.shape,  y_train.shape)
print ('Test set:', X_test.shape,  y_test.shape)

#Ahora haremos el modelado mediante la función LogisticRegression() de scikit-learn
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)
LR

#Ahora estamos listos para realizar una predicción utilizando nuestro set de prueba
yhat = LR.predict(X_test)
yhat

#Ahora, con la función predict.proba() obtendremos una estimación para cada clase, ordenada en función de su etiqueta de tal modo que la primera columna será la clase 0, la segunda la clase 1, etc.
yhat_prob = LR.predict_proba(X_test)
yhat_prob

#Evaluemos nuestro modelo. Para ello podemos utilizar varias formas. Veamos el índice de Jaccard, la matriz de confusión y la pérdida logarítmica
  #Índice de Jaccard
  from sklearn.metrics import jaccard_score
  jaccard_score(y_test, yhat,pos_label=0)
    #[OUT]: 0.7058823529411765
  
  #Matriz de confusión
  from sklearn.metrics import classification_report, confusion_matrix
  import itertools
  def plot_confusion_matrix(cm, classes,
                            normalize=False,
                            title='Confusion matrix',
                            cmap=plt.cm.Blues):
      """
      This function prints and plots the confusion matrix.
      Normalization can be applied by setting `normalize=True`.
      """
      if normalize:
          cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
          print("Normalized confusion matrix")
      else:
          print('Confusion matrix, without normalization')

      print(cm)

      plt.imshow(cm, interpolation='nearest', cmap=cmap)
      plt.title(title)
      plt.colorbar()
      tick_marks = np.arange(len(classes))
      plt.xticks(tick_marks, classes, rotation=45)
      plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
  print(confusion_matrix(y_test, yhat, labels=[1,0]))
    #[OUT]: [[ 6  9] \ [ 1 24]]
  
  # Compute confusion matrix
  cnf_matrix = confusion_matrix(y_test, yhat, labels=[1,0])
  np.set_printoptions(precision=2)


  # Plot non-normalized confusion matrix
  plt.figure()
  plot_confusion_matrix(cnf_matrix, classes=['churn=1','churn=0'],normalize= False,  title='Confusion matrix')
  
  print (classification_report(y_test, yhat))
    #[OUT]:               precision    recall  f1-score   support

                     0       0.73      0.96      0.83        25
                     1       0.86      0.40      0.55        15

              accuracy                           0.75        40
             macro avg       0.79      0.68      0.69        40
          weighted avg       0.78      0.75      0.72        40

  
  #Pérdida logarítmica
  from sklearn.metrics import log_loss
  log_loss(y_test, yhat_prob)
    #[OUT]:0.6017092478101185
    

#Contruyamos otro modelo de Regresión Logarítmica con nuevos valores en solver y regularization

  
  
